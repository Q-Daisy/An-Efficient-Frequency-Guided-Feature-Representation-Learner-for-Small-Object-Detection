# Ultralytics YOLO ğŸš€, AGPL-3.0 license
"""
WDC-Block: Wavelet Difference Convolution Block
ç»“åˆå°æ³¢å˜æ¢å’Œä¸­å¿ƒå·®åˆ†å·ç§¯çš„è½»é‡çº§æ¨¡å—ï¼Œç”¨äºæ›¿æ¢ YOLOv11 ä¸­çš„ C3k2

æ ¸å¿ƒè®¾è®¡ç†å¿µï¼š
1. ä½¿ç”¨ Haar å°æ³¢å˜æ¢å°†ç‰¹å¾åˆ†è§£ä¸º LLã€LHã€HLã€HH å››ä¸ªåˆ†é‡
2. åœ¨ LLï¼ˆä½é¢‘ï¼‰åˆ†æ”¯ä½¿ç”¨ä¸­å¿ƒå·®åˆ†å·ç§¯ï¼ˆCDCï¼‰å¢å¼ºè¾¹ç¼˜æ„ŸçŸ¥èƒ½åŠ›
3. å°†é«˜é¢‘åˆ†é‡ï¼ˆLH/HL/HHï¼‰ä½œä¸ºæ³¨æ„åŠ›é—¨æ§ï¼Œä¿®æ­£ä½é¢‘ç‰¹å¾
4. ä½¿ç”¨é‡å‚æ•°åŒ–æŠ€æœ¯ï¼Œæ¨ç†æ—¶ CDC é€€åŒ–ä¸ºæ™®é€šå·ç§¯ï¼Œä¿æŒè½»é‡åŒ–

è®¾è®¡ä¼˜åŠ¿ï¼š
- CDC å¯ä»¥åœ¨ H/2 åˆ†è¾¨ç‡ä¸‹æœ‰æ•ˆä¿ç•™å°ç›®æ ‡è¾¹ç¼˜ä¿¡æ¯
- é«˜é¢‘é—¨æ§æœºåˆ¶ä½¿ä½é¢‘ç‰¹å¾æ›´èšç„¦äºå…³é”®åŒºåŸŸ
- é‡å‚æ•°åŒ–ä¿è¯æ¨ç†é€Ÿåº¦ä¸æ™®é€šå·ç§¯ç›¸å½“
"""

import torch
import torch.nn as nn
import torch.nn.functional as F

from ultralytics.nn.modules.conv import Conv


class RDC(nn.Module):
    """
    Re-parameterized Central Difference Convolution (CDC)
    åŸºäº DEA-Net ç†è®ºçš„é‡å‚æ•°åŒ–ä¸­å¿ƒå·®åˆ†å·ç§¯
    
    è®­ç»ƒæ—¶ï¼šä½¿ç”¨ä¸­å¿ƒå·®åˆ†å·ç§¯å¢å¼ºè¾¹ç¼˜æ„ŸçŸ¥
    æ¨ç†æ—¶ï¼šåˆå¹¶ä¸ºæ™®é€šå·ç§¯ï¼Œä¿æŒé€Ÿåº¦
    """

    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, dilation=1, groups=1):
        super(RDC, self).__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.kernel_size = kernel_size
        self.stride = stride
        self.padding = padding
        self.dilation = dilation
        self.groups = groups

        # 1. æ™®é€šå·ç§¯æƒé‡
        self.weight = nn.Parameter(
            torch.Tensor(out_channels, in_channels // groups, kernel_size, kernel_size)
        )

        # 2. Theta å‚æ•°ç”¨äº CDCï¼ˆæ§åˆ¶å¼ºåº¦å’Œæ¢¯åº¦çš„æƒè¡¡ï¼‰
        # ä½¿ç”¨ 1x1 çš„ theta è¿›è¡Œé€é€šé“è°ƒæ•´
        self.theta = nn.Parameter(
            torch.Tensor(out_channels, in_channels // groups, 1, 1)
        )

        # åˆå§‹åŒ–
        nn.init.kaiming_normal_(self.weight, mode='fan_out', nonlinearity='relu')
        nn.init.constant_(self.theta, 0.0)

        self.is_deploy = False

    def forward(self, x):
        if self.is_deploy:
            # æ¨ç†æ¨¡å¼ï¼šç›´æ¥ä½¿ç”¨åˆå¹¶åçš„æƒé‡
            return F.conv2d(
                x, self.reparam_weight, None, self.stride, self.padding, self.dilation, self.groups
            )

        # è®­ç»ƒæ¨¡å¼ï¼šCDC = Vanilla Conv - Theta * Center
        # æ„é€  CDC å·ç§¯æ ¸ï¼šåœ¨ä¸­å¿ƒä½ç½®å‡å» theta
        kernel_cdc = self.weight.clone()
        center_idx = self.kernel_size // 2
        
        # åœ¨å·ç§¯æ ¸ä¸­å¿ƒä½ç½®å‡å» theta
        # theta çš„å½¢çŠ¶æ˜¯ [out_channels, in_channels//groups, 1, 1]
        # éœ€è¦å¹¿æ’­åˆ°å·ç§¯æ ¸çš„ä¸­å¿ƒä½ç½®
        kernel_cdc[:, :, center_idx, center_idx] -= self.theta.squeeze(-1).squeeze(-1)

        return F.conv2d(
            x, kernel_cdc, None, self.stride, self.padding, self.dilation, self.groups
        )

    def switch_to_deploy(self):
        """åˆ‡æ¢åˆ°éƒ¨ç½²æ¨¡å¼ï¼šåˆå¹¶å·ç§¯æ ¸"""
        if not self.is_deploy:
            center_idx = self.kernel_size // 2
            kernel_final = self.weight.clone()
            kernel_final[:, :, center_idx, center_idx] -= self.theta.squeeze(-1).squeeze(-1)

            self.reparam_weight = nn.Parameter(kernel_final.detach())
            # åˆ é™¤è®­ç»ƒæ—¶çš„å‚æ•°
            del self.weight
            del self.theta
            self.is_deploy = True


class WDG(nn.Module):
    """
    Wavelet Difference Gate (WDG) Block
    ä½œä¸º Bottleneck æ›¿æ¢ï¼Œç»“åˆå°æ³¢å˜æ¢å’Œå·®åˆ†å·ç§¯
    """

    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):
        """
        Args:
            c1: è¾“å…¥é€šé“æ•°
            c2: è¾“å‡ºé€šé“æ•°
            shortcut: æ˜¯å¦ä½¿ç”¨æ®‹å·®è¿æ¥
            g: åˆ†ç»„å·ç§¯ç»„æ•°
            e: æ‰©å±•æ¯”ä¾‹
        """
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        self.add = shortcut and c1 == c2

        # è¾“å…¥æŠ•å½±
        self.cv1 = Conv(c1, c_, 1, 1)

        # è¾“å‡ºæŠ•å½±
        self.cv2 = Conv(c_, c2, 1, 1)

        # --- ä½é¢‘åˆ†æ”¯ï¼ˆLLï¼‰ï¼šä½¿ç”¨ RDC å¢å¼ºè¾¹ç¼˜æ„ŸçŸ¥ ---
        self.cdc_ll = nn.Sequential(
            RDC(c_, c_, kernel_size=3, padding=1),
            nn.BatchNorm2d(c_),
            nn.SiLU()
        )

        # --- é«˜é¢‘åˆ†æ”¯ï¼ˆLH/HL/HHï¼‰ï¼šä½œä¸ºæ³¨æ„åŠ›é—¨æ§ ---
        # å°† 3 ä¸ªé«˜é¢‘åˆ†é‡èåˆä¸ºæ³¨æ„åŠ›å›¾
        self.hf_gate = nn.Sequential(
            nn.Conv2d(c_ * 3, c_, 1, 1, groups=1, bias=False),
            nn.BatchNorm2d(c_),
            nn.Sigmoid()  # ç”Ÿæˆ (0,1) çš„æƒé‡
        )

    def _haar_dwt(self, x):
        """
        Haar å°æ³¢å˜æ¢ï¼ˆæ‰‹åŠ¨å®ç°ï¼Œé¿å…ä¾èµ– pywtï¼‰
        å°†è¾“å…¥åˆ†è§£ä¸º LL, LH, HL, HH å››ä¸ªåˆ†é‡
        å¤„ç†å¥‡æ•°å°ºå¯¸çš„æƒ…å†µï¼Œç¡®ä¿æ‰€æœ‰åˆ‡ç‰‡å°ºå¯¸ä¸€è‡´
        """
        b, c, h, w = x.shape
        
        # å¦‚æœé«˜åº¦æˆ–å®½åº¦æ˜¯å¥‡æ•°ï¼Œè£å‰ªåˆ°å¶æ•°å°ºå¯¸
        h_even = h if h % 2 == 0 else h - 1
        w_even = w if w % 2 == 0 else w - 1
        x = x[:, :, :h_even, :w_even]
        
        # ä½¿ç”¨åˆ‡ç‰‡å®ç° 2x2 ä¸‹é‡‡æ ·
        # ç”±äºå·²ç»è£å‰ªåˆ°å¶æ•°ï¼Œæ‰€æœ‰åˆ‡ç‰‡åº”è¯¥æœ‰ç›¸åŒçš„å°ºå¯¸
        x0 = x[:, :, 0::2, 0::2]  # å·¦ä¸Š
        x1 = x[:, :, 0::2, 1::2]  # å³ä¸Š
        x2 = x[:, :, 1::2, 0::2]  # å·¦ä¸‹
        x3 = x[:, :, 1::2, 1::2]  # å³ä¸‹

        # ç¡®ä¿æ‰€æœ‰åˆ‡ç‰‡å°ºå¯¸ä¸€è‡´ï¼ˆå–æœ€å°å€¼ï¼Œå¤„ç†å¯èƒ½çš„è¾¹ç•Œæƒ…å†µï¼‰
        min_h = min(x0.shape[2], x1.shape[2], x2.shape[2], x3.shape[2])
        min_w = min(x0.shape[3], x1.shape[3], x2.shape[3], x3.shape[3])
        
        if min_h < x0.shape[2] or min_w < x0.shape[3]:
            x0 = x0[:, :, :min_h, :min_w]
            x1 = x1[:, :, :min_h, :min_w]
            x2 = x2[:, :, :min_h, :min_w]
            x3 = x3[:, :, :min_h, :min_w]

        # Haar å°æ³¢å˜æ¢å…¬å¼
        ll = (x0 + x1 + x2 + x3) / 2.0  # ä½é¢‘
        lh = (x0 - x1 + x2 - x3) / 2.0  # æ°´å¹³é«˜é¢‘
        hl = (x0 + x1 - x2 - x3) / 2.0  # å‚ç›´é«˜é¢‘
        hh = (x0 - x1 - x2 + x3) / 2.0  # å¯¹è§’é«˜é¢‘

        return ll, lh, hl, hh, h_even, w_even  # è¿”å›è£å‰ªåçš„å°ºå¯¸

    def _haar_idwt(self, ll, lh, hl, hh, target_h=None, target_w=None):
        """
        Haar å°æ³¢é€†å˜æ¢ï¼ˆé‡æ„ï¼‰
        å°†å››ä¸ªåˆ†é‡é‡æ„ä¸ºåŸå§‹åˆ†è¾¨ç‡
        """
        # é€†å˜æ¢å…¬å¼
        y0 = (ll + lh + hl + hh) / 2.0
        y1 = (ll - lh + hl - hh) / 2.0
        y2 = (ll + lh - hl - hh) / 2.0
        y3 = (ll - lh - hl + hh) / 2.0

        # è·å–ç©ºé—´å°ºå¯¸
        b, c, h, w = ll.shape

        # é‡æ„ä¸º 2H x 2W
        out_h = target_h if target_h is not None else h * 2
        out_w = target_w if target_w is not None else w * 2
        
        out = torch.zeros((b, c, out_h, out_w), device=ll.device, dtype=ll.dtype)
        
        # ä½¿ç”¨æ’å€¼æˆ–ç›´æ¥èµ‹å€¼é‡æ„
        # å¦‚æœç›®æ ‡å°ºå¯¸ä¸ 2H x 2W ä¸åŒï¼Œä½¿ç”¨æ’å€¼
        if out_h == h * 2 and out_w == w * 2:
            out[:, :, 0::2, 0::2] = y0
            out[:, :, 0::2, 1::2] = y1
            out[:, :, 1::2, 0::2] = y2
            out[:, :, 1::2, 1::2] = y3
        else:
            # å…ˆé‡æ„åˆ° 2H x 2Wï¼Œç„¶åæ’å€¼åˆ°ç›®æ ‡å°ºå¯¸
            temp = torch.zeros((b, c, h * 2, w * 2), device=ll.device, dtype=ll.dtype)
            temp[:, :, 0::2, 0::2] = y0
            temp[:, :, 0::2, 1::2] = y1
            temp[:, :, 1::2, 0::2] = y2
            temp[:, :, 1::2, 1::2] = y3
            out = F.interpolate(temp, size=(out_h, out_w), mode='bilinear', align_corners=False)

        return out

    def forward(self, x):
        # 1. è¾“å…¥æŠ•å½±
        x_in = self.cv1(x)

        # 2. Haar DWT åˆ†è§£ï¼ˆå†…éƒ¨ä¼šå¤„ç†å¥‡æ•°å°ºå¯¸ï¼‰
        ll, lh, hl, hh, h_even, w_even = self._haar_dwt(x_in)

        # 3. å¤„ç†ä½é¢‘åˆ†æ”¯ï¼šä½¿ç”¨ CDC å¢å¼ºè¾¹ç¼˜
        feat_ll = self.cdc_ll(ll)

        # 4. å¤„ç†é«˜é¢‘åˆ†æ”¯ï¼šç”Ÿæˆæ³¨æ„åŠ›é—¨æ§
        hf_cat = torch.cat([lh, hl, hh], dim=1)  # [B, 3*c_, H/2, W/2]
        feat_gate = self.hf_gate(hf_cat)  # [B, c_, H/2, W/2]

        # 5. é¢‘ç‡äº¤äº’ï¼šç”¨é«˜é¢‘ä¿¡æ¯ä¿®æ­£ä½é¢‘ç‰¹å¾
        # ä½¿ç”¨åŠ æ€§é—¨æ§ï¼š(1 + gate) å¢å¼ºå…³é”®åŒºåŸŸ
        ll_refined = feat_ll * (1.0 + feat_gate)

        # 6. ä¿æŒåŸå§‹é«˜é¢‘ä¿¡æ¯ï¼ˆå¯ä»¥é€‰æ‹©æ€§åœ°ä½¿ç”¨åŸå§‹æˆ–æ›´æ–°çš„é«˜é¢‘ï¼‰
        # è¿™é‡Œä½¿ç”¨åŸå§‹é«˜é¢‘ï¼Œä¿æŒçº¹ç†ç»†èŠ‚
        r_lh, r_hl, r_hh = lh, hl, hh

        # 7. é€†å°æ³¢å˜æ¢é‡æ„ï¼ˆæ¢å¤åˆ°è£å‰ªåçš„å¶æ•°å°ºå¯¸ï¼‰
        out = self._haar_idwt(ll_refined, r_lh, r_hl, r_hh, target_h=h_even, target_w=w_even)

        # 8. å¦‚æœåŸå§‹è¾“å…¥æ˜¯å¥‡æ•°å°ºå¯¸ï¼Œéœ€è¦æ’å€¼æˆ–è£å‰ªå›åŸå§‹å°ºå¯¸
        _, _, h_orig, w_orig = x_in.shape
        if out.shape[2] != h_orig or out.shape[3] != w_orig:
            out = F.interpolate(out, size=(h_orig, w_orig), mode='bilinear', align_corners=False)

        # 9. è¾“å‡ºæŠ•å½±
        out = self.cv2(out)

        # 10. æ®‹å·®è¿æ¥ï¼ˆå¦‚æœéœ€è¦ï¼‰
        return x + out if self.add else out


class C3_WDG(nn.Module):
    """
    C3 æ¨¡å—ï¼Œä½¿ç”¨ WDG ä½œä¸º Bottleneck
    æ›¿æ¢åŸå§‹çš„ C3k2 ä¸­çš„ Bottleneck
    """

    def __init__(self, c1, c2, n=1, c3k=False, e=0.5, g=1, shortcut=True):
        """
        Args:
            c1: è¾“å…¥é€šé“æ•°
            c2: è¾“å‡ºé€šé“æ•°
            n: Bottleneck é‡å¤æ¬¡æ•°
            c3k: æ˜¯å¦ä½¿ç”¨ C3kï¼ˆå…¼å®¹å‚æ•°ï¼Œå½“å‰ä¸æ”¯æŒï¼‰
            e: æ‰©å±•æ¯”ä¾‹
            g: åˆ†ç»„æ•°
            shortcut: æ˜¯å¦ä½¿ç”¨æ®‹å·®è¿æ¥
        """
        super().__init__()
        self.c = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, 2 * self.c, 1, 1)
        self.cv2 = Conv((2 + n) * self.c, c2, 1)

        # ä½¿ç”¨ WDG æ›¿æ¢åŸå§‹ Bottleneck
        if c3k:
            # å¦‚æœè¦æ±‚ä½¿ç”¨ C3kï¼Œæˆ‘ä»¬ä»ç„¶ä½¿ç”¨ WDGï¼ˆå› ä¸º C3k ä¹Ÿæ˜¯ Bottleneck çš„å˜ç§ï¼‰
            self.m = nn.ModuleList(
                WDG(self.c, self.c, shortcut, g, e=1.0) for _ in range(n)
            )
        else:
            self.m = nn.ModuleList(
                WDG(self.c, self.c, shortcut, g, e=1.0) for _ in range(n)
            )

    def forward(self, x):
        """å‰å‘ä¼ æ’­"""
        y = list(self.cv1(x).chunk(2, 1))
        y.extend(m(y[-1]) for m in self.m)
        return self.cv2(torch.cat(y, 1))

    def forward_split(self, x):
        """ä½¿ç”¨ split çš„å‰å‘ä¼ æ’­"""
        y = list(self.cv1(x).split((self.c, self.c), 1))
        y.extend(m(y[-1]) for m in self.m)
        return self.cv2(torch.cat(y, 1))


if __name__ == "__main__":
    # æµ‹è¯• WDG æ¨¡å—
    print("æµ‹è¯• WDG æ¨¡å—...")

    # ç”Ÿæˆæµ‹è¯•è¾“å…¥
    B, C1, H, W = 2, 64, 64, 64
    x = torch.randn(B, C1, H, W)
    print(f"è¾“å…¥å½¢çŠ¶: {x.shape}")

    # æµ‹è¯• RDC
    print("\næµ‹è¯• RDC...")
    cdc = RDC(64, 64, kernel_size=3, padding=1)
    out_cdc = cdc(x)
    print(f"RDC è¾“å‡ºå½¢çŠ¶: {out_cdc.shape}")
    
    # æµ‹è¯•åˆ‡æ¢åˆ°éƒ¨ç½²æ¨¡å¼
    cdc.switch_to_deploy()
    out_cdc_deploy = cdc(x)
    print(f"RDC (éƒ¨ç½²æ¨¡å¼) è¾“å‡ºå½¢çŠ¶: {out_cdc_deploy.shape}")
    print(f"è¾“å‡ºå·®å¼‚: {torch.abs(out_cdc - out_cdc_deploy).max().item():.6f}")

    # æµ‹è¯• WDG
    print("\næµ‹è¯• WDG...")
    wdg = WDG(c1=64, c2=64, shortcut=True)
    out_wdg = wdg(x)
    print(f"WDG è¾“å‡ºå½¢çŠ¶: {out_wdg.shape}")

    # æµ‹è¯• C3_WDG
    print("\næµ‹è¯• C3_WDG...")
    c3_wdg = C3_WDG(c1=64, c2=128, n=2, shortcut=True)
    out_c3_wdg = c3_wdg(x)
    print(f"C3_WDG è¾“å‡ºå½¢çŠ¶: {out_c3_wdg.shape}")

    # è®¡ç®—å‚æ•°é‡
    def count_parameters(model):
        return sum(p.numel() for p in model.parameters() if p.requires_grad)

    print("\nå‚æ•°é‡ç»Ÿè®¡:")
    print(f"RDC: {count_parameters(cdc):,} å‚æ•°")
    print(f"WDG: {count_parameters(wdg):,} å‚æ•°")
    print(f"C3_WDG: {count_parameters(c3_wdg):,} å‚æ•°")

    print("\næµ‹è¯•å®Œæˆï¼")

__all__ = [
    'RDC',
    'WDG',
    'C3_WDG',
]